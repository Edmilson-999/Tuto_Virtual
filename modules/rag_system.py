"""
modules/rag_system.py
Sistema RAG com correÃ§Ã£o de caminhos para Windows
"""

import os
import shutil
from dotenv import load_dotenv
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Suprimir warnings desnecessÃ¡rios
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

load_dotenv()

# Caminhos
DOCS_PATH = "data/docs/"
DB_PATH = "data/chroma_db/"

def carregar_embeddings_locais():
    """Carrega modelo de embeddings local"""
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        
        model_name = "sentence-transformers/all-MiniLM-L6-v2"
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': False}
        )
        
        print("âœ… Embeddings locais carregados")
        return embeddings
        
    except Exception as e:
        print(f"âŒ Erro ao carregar embeddings: {e}")
        raise

def criar_base_conhecimento(pdf_path: str):
    """Cria base de conhecimento a partir de PDF"""
    try:
        from langchain_community.document_loaders import PyPDFLoader
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_chroma import Chroma
        
        # Verificar se arquivo existe
        if not os.path.exists(pdf_path):
            print(f"   âŒ Arquivo nÃ£o encontrado: {pdf_path}")
            return None
            
        # Carregar PDF
        loader = PyPDFLoader(pdf_path)
        documentos = loader.load()
        
        if not documentos:
            print(f"   âš ï¸ PDF vazio ou corrompido: {pdf_path}")
            return None

        # Dividir texto
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100
        )
        chunks = splitter.split_documents(documentos)
        
        print(f"   ğŸ“„ Criados {len(chunks)} chunks")

        # Embeddings locais
        embeddings = carregar_embeddings_locais()

        # Criar vector store
        vector_store = Chroma.from_documents(
            documents=chunks,
            embedding=embeddings,
            persist_directory=DB_PATH
        )
        
        print(f"   âœ… PDF processado com sucesso")
        return vector_store
        
    except Exception as e:
        print(f"   âŒ Erro ao processar PDF: {e}")
        return None

def carregar_base_conhecimento():
    """Carrega base existente"""
    try:
        from langchain_chroma import Chroma
        
        if not os.path.exists(DB_PATH) or not os.listdir(DB_PATH):
            return None

        embeddings = carregar_embeddings_locais()
        vector_store = Chroma(
            persist_directory=DB_PATH,
            embedding_function=embeddings
        )
        
        # Testar se funciona
        count = vector_store._collection.count()
        print(f"âœ… Base carregada com {count} documentos")
        return vector_store
        
    except Exception as e:
        print(f"âŒ Erro ao carregar base: {e}")
        return None

def inicializar_sistema_rag():
    """Inicializa sistema RAG"""
    try:
        # Verificar API key do Mistral
        mistral_key = os.getenv("MISTRAL_API_KEY")
        if not mistral_key:
            print("âš ï¸ Mistral API key nÃ£o configurada")
            return None, None

        # Carregar base
        vector_store = carregar_base_conhecimento()
        if not vector_store:
            print("â„¹ï¸ Nenhuma base encontrada. Adicione PDFs primeiro.")
            return None, None

        # Configurar LLM
        from langchain_mistralai import ChatMistralAI
        llm = ChatMistralAI(
            model="mistral-small-latest",
            api_key=mistral_key,
            temperature=0.6
        )

        # Configurar retriever
        retriever = vector_store.as_retriever(search_kwargs={"k": 3})

        # Criar QA chain
        from langchain.chains import RetrievalQA
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True
        )
        
        print("ğŸš€ Sistema RAG inicializado com sucesso")
        return qa_chain, vector_store
        
    except Exception as e:
        print(f"âŒ Erro ao inicializar RAG: {e}")
        return None, None

def processar_todos_pdfs():
    """Processa todos os PDFs com caminhos corrigidos"""
    try:
        from utils.helpers import listar_pdfs, get_caminho_pdf, verificar_pdf_valido
        
        pdfs = listar_pdfs()
        if not pdfs:
            print("ğŸ“­ Nenhum PDF encontrado em data/docs/")
            return False

        print(f"ğŸ“š Encontrados {len(pdfs)} PDFs para processar")
        
        # Limpar base anterior
        if os.path.exists(DB_PATH):
            shutil.rmtree(DB_PATH)
            print("ğŸ§¹ Base anterior removida")

        success_count = 0
        for pdf_nome in pdfs:
            try:
                # Obter caminho correto
                pdf_path = get_caminho_pdf(pdf_nome)
                
                print(f"ğŸ“˜ Processando: {pdf_nome}")
                
                # Verificar se o arquivo existe
                if not verificar_pdf_valido(pdf_path):
                    print(f"   âŒ Arquivo invÃ¡lido: {pdf_path}")
                    continue
                
                # Processar PDF
                if criar_base_conhecimento(pdf_path):
                    success_count += 1
                    print(f"   âœ… Sucesso")
                else:
                    print(f"   âŒ Falha")
                    
            except Exception as e:
                print(f"   âŒ Erro: {e}")
                continue

        if success_count > 0:
            print(f"ğŸ‰ {success_count}/{len(pdfs)} PDFs processados com sucesso!")
            
            # Recarregar sistema RAG
            global qa_chain, vector_store
            qa_chain, vector_store = inicializar_sistema_rag()
            
            return True
        else:
            print("âŒ Nenhum PDF pÃ´de ser processado")
            return False
            
    except Exception as e:
        print(f"âŒ Erro no processamento: {e}")
        return False

def limpar_base_conhecimento():
    """Limpa a base de dados"""
    try:
        if os.path.exists(DB_PATH):
            shutil.rmtree(DB_PATH)
            print("ğŸ§¹ Base de conhecimento limpa")
            return True
        return False
    except Exception as e:
        print(f"âŒ Erro ao limpar base: {e}")
        return False

# InicializaÃ§Ã£o
qa_chain, vector_store = inicializar_sistema_rag()

# Teste
if __name__ == "__main__":
    print("ğŸ§ª Testando sistema RAG...")
    
    # Testar se PDFs estÃ£o acessÃ­veis
    from utils.helpers import listar_pdfs, get_caminho_pdf
    
    pdfs = listar_pdfs()
    print(f"ğŸ“ PDFs encontrados: {len(pdfs)}")
    
    for pdf in pdfs:
        caminho = get_caminho_pdf(pdf)
        existe = os.path.exists(caminho)
        print(f"   {pdf}: {'âœ…' if existe else 'âŒ'} {caminho}")
    
    # Testar embeddings
    try:
        embeddings = carregar_embeddings_locais()
        test_vector = embeddings.embed_query("teste")
        print(f"âœ… Embeddings: {len(test_vector)} dimensÃµes")
    except Exception as e:
        print(f"âŒ Erro nos embeddings: {e}")
    
    # Testar base
    base = carregar_base_conhecimento()
    if base:
        print("âœ… Base carregada - sistema pronto!")
    else:
        print("â„¹ï¸ Execute o processamento de PDFs primeiro")
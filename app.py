# app.py (parte atualizada)
import streamlit as st
import os

# Importa√ß√µes dos m√≥dulos internos
from modules.chatbot import gerar_resposta, load_llm
from modules.rag_system import qa_chain, criar_base_conhecimento, inicializar_sistema_rag
from utils.helpers import listar_pdfs

# ---------------- CONFIGURA√á√ÉO ----------------
st.set_page_config(page_title="Tutor Virtual Inteligente", page_icon="ü§ñ")

st.title("üéì Tutor Virtual Inteligente com IA e RAG")
st.write("""
Bem-vindo! Este tutor combina **IA conversacional** com **busca em documentos (RAG)** 
para responder √†s suas perguntas de forma personalizada e contextualizada.
""")

# ---------------- BASE DE CONHECIMENTO ----------------
st.sidebar.header("üìö Base de Conhecimento")

pdfs = listar_pdfs()

if not pdfs:
    st.sidebar.warning("‚ö†Ô∏è Nenhum documento encontrado em `data/docs/`.")
    st.sidebar.info("Adicione arquivos PDF na pasta `data/docs/` para o tutor poder estudar.")
else:
    st.sidebar.success(f"{len(pdfs)} documento(s) dispon√≠vel(is).")
    for pdf in pdfs:
        st.sidebar.write(f"‚Ä¢ {pdf}")

# Bot√£o para atualizar base
if st.sidebar.button("üîÑ Atualizar base de conhecimento"):
    if not pdfs:
        st.sidebar.error("‚ùå Nenhum PDF encontrado para processar.")
    else:
        with st.spinner("A processar documentos..."):
            try:
                for pdf in pdfs:
                    caminho = os.path.join("data/docs", pdf)
                    criar_base_conhecimento(caminho)
                # Reinicializar o sistema RAG ap√≥s atualiza√ß√£o
               # global qa_chain
                qa_chain, _ = inicializar_sistema_rag()
                st.sidebar.success("‚úÖ Base de conhecimento atualizada com sucesso!")
            except Exception as e:
                st.sidebar.error(f"‚ùå Erro ao processar documentos: {e}")

st.sidebar.markdown("---")
st.sidebar.info("üí¨ Use o campo abaixo para conversar com o tutor.")

# ---------------- INTERFACE DE CHAT ----------------
st.subheader("üí¨ Fa√ßa uma pergunta")

pergunta = st.text_input("Digite sua pergunta aqui:")

# Verificar se o sistema RAG est√° dispon√≠vel
rag_disponivel = qa_chain is not None and pdfs

if rag_disponivel:
    modo = st.radio(
        "Escolha o modo de resposta:",
        ["Com base nos PDFs (RAG)", "Somente Chatbot Base"],
        index=0
    )
else:
    st.info("‚ÑπÔ∏è Modo RAG indispon√≠vel. Verifique se h√° PDFs na pasta `data/docs/` e se as API keys est√£o configuradas.")
    modo = "Somente Chatbot Base"

# Op√ß√£o para alternar entre modelos
modelo_escolhido = st.selectbox(
    "üß† Escolha o modelo de IA:",
    ["Mistral", "OpenAI GPT-4"],
    index=0
)

# ---------------- PROCESSAMENTO ----------------
if pergunta:
    with st.spinner("A pensar... ü§î"):
        try:
            if modo == "Com base nos PDFs (RAG)" and rag_disponivel:
                resposta = qa_chain.invoke({"query": pergunta})
                st.markdown(f"**ü§ñ Tutor (com RAG):** {resposta['result']}")
                
                # Mostrar fontes (opcional)
                with st.expander("üìö Ver fontes utilizadas"):
                    for i, doc in enumerate(resposta.get('source_documents', [])[:2]):
                        st.write(f"Fonte {i+1}: {doc.metadata.get('source', 'Desconhecida')}")
                        st.caption(doc.page_content[:200] + "...")
            else:
                # Carregar modelo escolhido dinamicamente
                llm = load_llm(modelo=modelo_escolhido)
                resposta = gerar_resposta(pergunta, llm)
                st.markdown(f"**ü§ñ Tutor:** {resposta}")
                
        except Exception as e:
            st.error(f"‚ùå Ocorreu um erro: {e}")
            st.info("üí° Tente usar o modo 'Somente Chatbot Base' ou verifique a conex√£o com a API.")

# ---------------- RODAP√â ----------------
st.markdown("---")
st.caption("Desenvolvido como parte do TCC ‚Äî Tutor Virtual Inteligente com IA e Recomenda√ß√£o de Conte√∫dos üí°")